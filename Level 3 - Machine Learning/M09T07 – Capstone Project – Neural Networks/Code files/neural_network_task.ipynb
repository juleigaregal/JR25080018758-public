{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Capstone Project: Slogan Classifier and Generator\n",
        "\n",
        "In this capstone project you will train a Long Short-Term Memory (LSTM) model to generate slogans for businesses based on their industry, and also train a classifier to predict the industry based on a given slogan."
      ],
      "metadata": {
        "id": "zTMqss9QlpKl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Libraries\n",
        "We recommend running this notebook using [Google Colab](https://colab.google/) however if you choose to use your local machine you will need to install spaCy before starting.\n",
        "\n",
        "To install spaCy, refer to the installation instructions provided on the spaCy [website](https://spacy.io/usage). Note you may need to install an older version of Python that is compatible with spaCy. You can create a virtual environment for this project to install the specific version of Python that you need."
      ],
      "metadata": {
        "id": "R11lkWvYvXC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import spacy # available on Google Colab\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "XU54-5mpnujt"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading and viewing the dataset\n",
        "\n",
        "- Load the slogan dataset into a variable called data.\n",
        "- Extract relevant columns in a variable called df.\n",
        "- Handle missing values.\n",
        "\n",
        "Do **not** change the column names.\n",
        "\n",
        "If you are using Google Colab you will need mount your Google Drive as follows:  \n",
        "`from google.colab import drive`  \n",
        "`drive.mount('/content/drive')`  \n",
        "\n",
        "The path you use when loading your data will look something like this if you are using your Google Drive:  \n",
        "\"/content/drive/MyDrive/Colab Notebooks/slogan-valid.csv\""
      ],
      "metadata": {
        "id": "aedbu0lBovia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "#uploaded = files.upload()\n",
        "\n",
        "# Assuming the file is named 'slogan-valid.csv'\n",
        "import pandas as pd\n",
        "df = pd.read_csv('slogan-valid.csv')\n",
        "\n",
        "# Display the first few rows\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "OH39XzGKpTpX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "7abcdc88-4a9d-405d-d470-12393f514642"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d275f897-cc51-4d2f-92a7-866a5cc8bec7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d275f897-cc51-4d2f-92a7-866a5cc8bec7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving slogan-valid.csv to slogan-valid.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                desc  \\\n",
              "0  The latest <company> & Point of Sale tech for ...   \n",
              "1  Easily deliver personalized activities that en...   \n",
              "2  Powerful lead generation software that convert...   \n",
              "3  Twine matches companies to the best digital an...   \n",
              "4  Financial Advisers Norwich, Norfolk - <company...   \n",
              "\n",
              "                                              output           type  \\\n",
              "0           Taking Care of Small Business Technology  headline_long   \n",
              "1              Build World-Class Recreation Programs       headline   \n",
              "2  Most Powerful Lead Generation Software for Mar...  headline_long   \n",
              "3              Hire quality freelancers for your job  headline_long   \n",
              "4                Financial Advisers Norwich, Norfolk       headline   \n",
              "\n",
              "                      company                      industry  \\\n",
              "0            eftpos warehouse             computer hardware   \n",
              "1                       welbi  health, wellness and fitness   \n",
              "2                optinmonster                      internet   \n",
              "3                    twine.fm                      internet   \n",
              "4  mcb financial services ltd            financial services   \n",
              "\n",
              "                          url                   alias  \\\n",
              "0       eftposwarehouse.co.nz        Eftpos Warehouse   \n",
              "1                    welbi.co                   Welbi   \n",
              "2            optinmonster.com            Optinmonster   \n",
              "3                    twine.fm                     NaN   \n",
              "4  mcbfinancialservices.co.uk  Mcb Financial Services   \n",
              "\n",
              "                                         desc_masked  \\\n",
              "0  The latest <company> & Point of Sale tech for ...   \n",
              "1  Easily deliver personalized activities that en...   \n",
              "2  Powerful lead generation software that convert...   \n",
              "3  Twine matches companies to the best digital an...   \n",
              "4  Financial Advisers [country], [country1] - <co...   \n",
              "\n",
              "                                       output_masked  \\\n",
              "0           Taking Care of Small Business Technology   \n",
              "1              Build World-Class Recreation Programs   \n",
              "2  Most Powerful Lead Generation Software for Mar...   \n",
              "3              Hire quality freelancers for your job   \n",
              "4           Financial Advisers [country], [country1]   \n",
              "\n",
              "                                            ent_dict  unsupported first_pos  \n",
              "0                              {'[date]': 'monthly'}        False        VB  \n",
              "1                                                 {}        False        VB  \n",
              "2                                                 {}        False        JJ  \n",
              "3                       {'[number]': 'over 260,000'}        False        VB  \n",
              "4  {'[country]': 'Norwich', '[country1]': 'Norfolk'}        False        NN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f143ef22-519a-419b-9b80-eb6403b8f008\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>desc</th>\n",
              "      <th>output</th>\n",
              "      <th>type</th>\n",
              "      <th>company</th>\n",
              "      <th>industry</th>\n",
              "      <th>url</th>\n",
              "      <th>alias</th>\n",
              "      <th>desc_masked</th>\n",
              "      <th>output_masked</th>\n",
              "      <th>ent_dict</th>\n",
              "      <th>unsupported</th>\n",
              "      <th>first_pos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The latest &lt;company&gt; &amp; Point of Sale tech for ...</td>\n",
              "      <td>Taking Care of Small Business Technology</td>\n",
              "      <td>headline_long</td>\n",
              "      <td>eftpos warehouse</td>\n",
              "      <td>computer hardware</td>\n",
              "      <td>eftposwarehouse.co.nz</td>\n",
              "      <td>Eftpos Warehouse</td>\n",
              "      <td>The latest &lt;company&gt; &amp; Point of Sale tech for ...</td>\n",
              "      <td>Taking Care of Small Business Technology</td>\n",
              "      <td>{'[date]': 'monthly'}</td>\n",
              "      <td>False</td>\n",
              "      <td>VB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Easily deliver personalized activities that en...</td>\n",
              "      <td>Build World-Class Recreation Programs</td>\n",
              "      <td>headline</td>\n",
              "      <td>welbi</td>\n",
              "      <td>health, wellness and fitness</td>\n",
              "      <td>welbi.co</td>\n",
              "      <td>Welbi</td>\n",
              "      <td>Easily deliver personalized activities that en...</td>\n",
              "      <td>Build World-Class Recreation Programs</td>\n",
              "      <td>{}</td>\n",
              "      <td>False</td>\n",
              "      <td>VB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Powerful lead generation software that convert...</td>\n",
              "      <td>Most Powerful Lead Generation Software for Mar...</td>\n",
              "      <td>headline_long</td>\n",
              "      <td>optinmonster</td>\n",
              "      <td>internet</td>\n",
              "      <td>optinmonster.com</td>\n",
              "      <td>Optinmonster</td>\n",
              "      <td>Powerful lead generation software that convert...</td>\n",
              "      <td>Most Powerful Lead Generation Software for Mar...</td>\n",
              "      <td>{}</td>\n",
              "      <td>False</td>\n",
              "      <td>JJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Twine matches companies to the best digital an...</td>\n",
              "      <td>Hire quality freelancers for your job</td>\n",
              "      <td>headline_long</td>\n",
              "      <td>twine.fm</td>\n",
              "      <td>internet</td>\n",
              "      <td>twine.fm</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Twine matches companies to the best digital an...</td>\n",
              "      <td>Hire quality freelancers for your job</td>\n",
              "      <td>{'[number]': 'over 260,000'}</td>\n",
              "      <td>False</td>\n",
              "      <td>VB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Financial Advisers Norwich, Norfolk - &lt;company...</td>\n",
              "      <td>Financial Advisers Norwich, Norfolk</td>\n",
              "      <td>headline</td>\n",
              "      <td>mcb financial services ltd</td>\n",
              "      <td>financial services</td>\n",
              "      <td>mcbfinancialservices.co.uk</td>\n",
              "      <td>Mcb Financial Services</td>\n",
              "      <td>Financial Advisers [country], [country1] - &lt;co...</td>\n",
              "      <td>Financial Advisers [country], [country1]</td>\n",
              "      <td>{'[country]': 'Norwich', '[country1]': 'Norfolk'}</td>\n",
              "      <td>False</td>\n",
              "      <td>NN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f143ef22-519a-419b-9b80-eb6403b8f008')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f143ef22-519a-419b-9b80-eb6403b8f008 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f143ef22-519a-419b-9b80-eb6403b8f008');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "Since we are working with textual data, we need software that understands natural language. For this, we'll use a library for processing text called **spaCy**. Using spaCy, we'll break the text into smaller units called tokens that are easier for the machine to process. This process is called **tokenisation**. We'll also convert all text to lowercase and remove punctuation because this information is not necessary for our models. Run the code below, and your dataframe (df) will gain a new column called **'processed_slogan'** which contains the preprocessed text.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wj6Whax7nSxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load spaCy model for text processing\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Define text preprocessing function\n",
        "def preprocess_text(text):\n",
        "    text_lower = text.lower()\n",
        "    doc = nlp(text_lower)\n",
        "\n",
        "    processed_tokens = []\n",
        "\n",
        "    for token in doc:\n",
        "        if not token.is_punct:\n",
        "            processed_tokens.append(token.text)\n",
        "\n",
        "    return \" \".join(processed_tokens)\n",
        "\n",
        "df[\"processed_slogan\"] = df[\"output\"].apply(preprocess_text)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "ZcIWV7IXp9rt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "outputId": "5a58631b-a329-49bb-9aa7-f48fea36261c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                desc  \\\n",
              "0  The latest <company> & Point of Sale tech for ...   \n",
              "1  Easily deliver personalized activities that en...   \n",
              "2  Powerful lead generation software that convert...   \n",
              "3  Twine matches companies to the best digital an...   \n",
              "4  Financial Advisers Norwich, Norfolk - <company...   \n",
              "\n",
              "                                              output           type  \\\n",
              "0           Taking Care of Small Business Technology  headline_long   \n",
              "1              Build World-Class Recreation Programs       headline   \n",
              "2  Most Powerful Lead Generation Software for Mar...  headline_long   \n",
              "3              Hire quality freelancers for your job  headline_long   \n",
              "4                Financial Advisers Norwich, Norfolk       headline   \n",
              "\n",
              "                      company                      industry  \\\n",
              "0            eftpos warehouse             computer hardware   \n",
              "1                       welbi  health, wellness and fitness   \n",
              "2                optinmonster                      internet   \n",
              "3                    twine.fm                      internet   \n",
              "4  mcb financial services ltd            financial services   \n",
              "\n",
              "                          url                   alias  \\\n",
              "0       eftposwarehouse.co.nz        Eftpos Warehouse   \n",
              "1                    welbi.co                   Welbi   \n",
              "2            optinmonster.com            Optinmonster   \n",
              "3                    twine.fm                     NaN   \n",
              "4  mcbfinancialservices.co.uk  Mcb Financial Services   \n",
              "\n",
              "                                         desc_masked  \\\n",
              "0  The latest <company> & Point of Sale tech for ...   \n",
              "1  Easily deliver personalized activities that en...   \n",
              "2  Powerful lead generation software that convert...   \n",
              "3  Twine matches companies to the best digital an...   \n",
              "4  Financial Advisers [country], [country1] - <co...   \n",
              "\n",
              "                                       output_masked  \\\n",
              "0           Taking Care of Small Business Technology   \n",
              "1              Build World-Class Recreation Programs   \n",
              "2  Most Powerful Lead Generation Software for Mar...   \n",
              "3              Hire quality freelancers for your job   \n",
              "4           Financial Advisers [country], [country1]   \n",
              "\n",
              "                                            ent_dict  unsupported first_pos  \\\n",
              "0                              {'[date]': 'monthly'}        False        VB   \n",
              "1                                                 {}        False        VB   \n",
              "2                                                 {}        False        JJ   \n",
              "3                       {'[number]': 'over 260,000'}        False        VB   \n",
              "4  {'[country]': 'Norwich', '[country1]': 'Norfolk'}        False        NN   \n",
              "\n",
              "                                    processed_slogan  \n",
              "0           taking care of small business technology  \n",
              "1              build world class recreation programs  \n",
              "2  most powerful lead generation software for mar...  \n",
              "3              hire quality freelancers for your job  \n",
              "4                 financial advisers norwich norfolk  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3090501d-aaa8-4f74-a22c-ff5d8081c490\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>desc</th>\n",
              "      <th>output</th>\n",
              "      <th>type</th>\n",
              "      <th>company</th>\n",
              "      <th>industry</th>\n",
              "      <th>url</th>\n",
              "      <th>alias</th>\n",
              "      <th>desc_masked</th>\n",
              "      <th>output_masked</th>\n",
              "      <th>ent_dict</th>\n",
              "      <th>unsupported</th>\n",
              "      <th>first_pos</th>\n",
              "      <th>processed_slogan</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The latest &lt;company&gt; &amp; Point of Sale tech for ...</td>\n",
              "      <td>Taking Care of Small Business Technology</td>\n",
              "      <td>headline_long</td>\n",
              "      <td>eftpos warehouse</td>\n",
              "      <td>computer hardware</td>\n",
              "      <td>eftposwarehouse.co.nz</td>\n",
              "      <td>Eftpos Warehouse</td>\n",
              "      <td>The latest &lt;company&gt; &amp; Point of Sale tech for ...</td>\n",
              "      <td>Taking Care of Small Business Technology</td>\n",
              "      <td>{'[date]': 'monthly'}</td>\n",
              "      <td>False</td>\n",
              "      <td>VB</td>\n",
              "      <td>taking care of small business technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Easily deliver personalized activities that en...</td>\n",
              "      <td>Build World-Class Recreation Programs</td>\n",
              "      <td>headline</td>\n",
              "      <td>welbi</td>\n",
              "      <td>health, wellness and fitness</td>\n",
              "      <td>welbi.co</td>\n",
              "      <td>Welbi</td>\n",
              "      <td>Easily deliver personalized activities that en...</td>\n",
              "      <td>Build World-Class Recreation Programs</td>\n",
              "      <td>{}</td>\n",
              "      <td>False</td>\n",
              "      <td>VB</td>\n",
              "      <td>build world class recreation programs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Powerful lead generation software that convert...</td>\n",
              "      <td>Most Powerful Lead Generation Software for Mar...</td>\n",
              "      <td>headline_long</td>\n",
              "      <td>optinmonster</td>\n",
              "      <td>internet</td>\n",
              "      <td>optinmonster.com</td>\n",
              "      <td>Optinmonster</td>\n",
              "      <td>Powerful lead generation software that convert...</td>\n",
              "      <td>Most Powerful Lead Generation Software for Mar...</td>\n",
              "      <td>{}</td>\n",
              "      <td>False</td>\n",
              "      <td>JJ</td>\n",
              "      <td>most powerful lead generation software for mar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Twine matches companies to the best digital an...</td>\n",
              "      <td>Hire quality freelancers for your job</td>\n",
              "      <td>headline_long</td>\n",
              "      <td>twine.fm</td>\n",
              "      <td>internet</td>\n",
              "      <td>twine.fm</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Twine matches companies to the best digital an...</td>\n",
              "      <td>Hire quality freelancers for your job</td>\n",
              "      <td>{'[number]': 'over 260,000'}</td>\n",
              "      <td>False</td>\n",
              "      <td>VB</td>\n",
              "      <td>hire quality freelancers for your job</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Financial Advisers Norwich, Norfolk - &lt;company...</td>\n",
              "      <td>Financial Advisers Norwich, Norfolk</td>\n",
              "      <td>headline</td>\n",
              "      <td>mcb financial services ltd</td>\n",
              "      <td>financial services</td>\n",
              "      <td>mcbfinancialservices.co.uk</td>\n",
              "      <td>Mcb Financial Services</td>\n",
              "      <td>Financial Advisers [country], [country1] - &lt;co...</td>\n",
              "      <td>Financial Advisers [country], [country1]</td>\n",
              "      <td>{'[country]': 'Norwich', '[country1]': 'Norfolk'}</td>\n",
              "      <td>False</td>\n",
              "      <td>NN</td>\n",
              "      <td>financial advisers norwich norfolk</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3090501d-aaa8-4f74-a22c-ff5d8081c490')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3090501d-aaa8-4f74-a22c-ff5d8081c490 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3090501d-aaa8-4f74-a22c-ff5d8081c490');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want our model to generate **industry-specific** slogans. If we use the 'processed_slogan' column as it is, we'll be leaving out crucial context - the industries of the companies behind those slogans. To fix this, we'll create a new **'modified_slogan'** column that adds the industry name to the front of processed slogan.  \n",
        "\n",
        "For example:  \n",
        "\n",
        "> industry = 'computer hardware'  \n",
        "processed_slogan = 'taking care of small business technology'  \n",
        "modified_slogan = 'computer hardware taking care of small business technology'\n",
        "\n",
        "Write code in the cell below to achieve this."
      ],
      "metadata": {
        "id": "tXpVm-kItirs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine 'industry' and 'processed_slogan' into a new column 'modified_slogan'\n",
        "\n",
        "# The lambda function adds the industry name before the processed slogan\n",
        "df['modified_slogan'] = df.apply(lambda row: f\"{row['industry']} {row['processed_slogan']}\", axis=1)\n",
        "\n",
        "# Display the first few rows to verify the result\n",
        "df[['industry', 'processed_slogan', 'modified_slogan']].head()\n"
      ],
      "metadata": {
        "id": "VLNM3yK7ti6x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "646f44a2-4117-46af-a083-70c93a36fc52"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       industry  \\\n",
              "0             computer hardware   \n",
              "1  health, wellness and fitness   \n",
              "2                      internet   \n",
              "3                      internet   \n",
              "4            financial services   \n",
              "\n",
              "                                    processed_slogan  \\\n",
              "0           taking care of small business technology   \n",
              "1              build world class recreation programs   \n",
              "2  most powerful lead generation software for mar...   \n",
              "3              hire quality freelancers for your job   \n",
              "4                 financial advisers norwich norfolk   \n",
              "\n",
              "                                     modified_slogan  \n",
              "0  computer hardware taking care of small busines...  \n",
              "1  health, wellness and fitness build world class...  \n",
              "2  internet most powerful lead generation softwar...  \n",
              "3     internet hire quality freelancers for your job  \n",
              "4  financial services financial advisers norwich ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-068761de-3ae7-4cc6-89da-f34ff7579233\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>industry</th>\n",
              "      <th>processed_slogan</th>\n",
              "      <th>modified_slogan</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>computer hardware</td>\n",
              "      <td>taking care of small business technology</td>\n",
              "      <td>computer hardware taking care of small busines...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>health, wellness and fitness</td>\n",
              "      <td>build world class recreation programs</td>\n",
              "      <td>health, wellness and fitness build world class...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>internet</td>\n",
              "      <td>most powerful lead generation software for mar...</td>\n",
              "      <td>internet most powerful lead generation softwar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>internet</td>\n",
              "      <td>hire quality freelancers for your job</td>\n",
              "      <td>internet hire quality freelancers for your job</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>financial services</td>\n",
              "      <td>financial advisers norwich norfolk</td>\n",
              "      <td>financial services financial advisers norwich ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-068761de-3ae7-4cc6-89da-f34ff7579233')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-068761de-3ae7-4cc6-89da-f34ff7579233 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-068761de-3ae7-4cc6-89da-f34ff7579233');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to get data to train our model. We have textual data which we will need to represent numerically for our model to learn from it.  \n",
        "The code below does the following:\n",
        "1. Tokenizes a dataset of slogans.\n",
        "2. Converts words to numerical indices.\n",
        "3. Creates input sequences using the numerical indices.  \n",
        "\n",
        "Here's how it works. From the 'modified_slogan' column, we take the slogan \"computer hardware taking care of small business technology\". The tokenisation process will convert words into their corresponding indices:  \n",
        "\n",
        "<center>\n",
        "\n",
        "| Word         | Token Index |\n",
        "|-------------|-------|\n",
        "| \"computer\"  | 1     |\n",
        "| \"hardware\"  | 2     |\n",
        "| \"taking\"    | 3     |\n",
        "| \"care\"      | 4     |\n",
        "| \"of\"        | 5     |\n",
        "| \"small\"     | 6     |\n",
        "| \"business\"  | 7     |\n",
        "| \"technology\"| 8     |\n",
        "\n",
        "</center>\n",
        "\n",
        "So the tokenized list is:\n",
        "\n",
        "<center>\n",
        "[1, 2, 3, 4, 5, 6, 7, 8]\n",
        "</center>\n",
        "\n",
        "When creating input sequences for training, the loop generates progressively longer sequences.\n",
        "\n",
        "<center>\n",
        "\n",
        "| Token Index Sequence               | Corresponding Slogan                                 |\n",
        "|------------------------------|-----------------------------------------------------|\n",
        "| [1, 2]                       | \"computer hardware\"                                |\n",
        "| [1, 2, 3]                    | \"computer hardware taking\"                        |\n",
        "| [1, 2, 3, 4]                 | \"computer hardware taking care\"                   |\n",
        "| [1, 2, 3, 4, 5]              | \"computer hardware taking care of\"                |\n",
        "| [1, 2, 3, 4, 5, 6]           | \"computer hardware taking care of small\"          |\n",
        "| [1, 2, 3, 4, 5, 6, 7]        | \"computer hardware taking care of small business\" |\n",
        "| [1, 2, 3, 4, 5, 6, 7, 8]     | \"computer hardware taking care of small business technology\" |\n",
        "\n",
        "</center>\n",
        "\n",
        "Instead of training the model on only **complete slogans**, we provide partial phrases which will help the model learn how words connect over time. This will make it better at predicting the next word when generating slogans.  \n",
        "\n",
        "Run the cell block below to generate the input sequences. Be sure to read the comments to understand what the code is doing.\n"
      ],
      "metadata": {
        "id": "_AJyWXVnwyNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Tokenizer from Keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# Fit the tokenizer on the modified slogans\n",
        "tokenizer.fit_on_texts(df['modified_slogan'])\n",
        "\n",
        "# Convert each slogan into a list of token indices\n",
        "token_list = tokenizer.texts_to_sequences(df['modified_slogan'])\n",
        "\n",
        "# Prepare input sequences for training\n",
        "input_sequences = []\n",
        "\n",
        "for tokens in token_list:\n",
        "    for i in range(2, len(tokens) + 1):\n",
        "        sequence = tokens[:i]\n",
        "        input_sequences.append(sequence)\n",
        "\n",
        "# Check the first few sequences\n",
        "for i in range(5):\n",
        "    print(input_sequences[i])\n",
        "\n",
        "# Vocabulary size (+1 for reserved index 0)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(\"\\nVocabulary size:\", vocab_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtHMI_Y1BXiP",
        "outputId": "2cfd7731-c7e9-4bbb-b452-ba2953e3e7ea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11, 236]\n",
            "[11, 236, 2708]\n",
            "[11, 236, 2708, 23]\n",
            "[11, 236, 2708, 23, 24]\n",
            "[11, 236, 2708, 23, 24, 414]\n",
            "\n",
            "Vocabulary size: 6046\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# Fit tokenizer on the modified slogans\n",
        "tokenizer.fit_on_texts(df[\"modified_slogan\"])\n",
        "\n",
        "# Get total number of unique words (+1 for reserved index 0)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Display the word index mapping (word  token index)\n",
        "tokenizer.word_index\n",
        "\n",
        "# Create input sequences for the slogan generator\n",
        "input_sequences = []\n",
        "\n",
        "for line in df[\"modified_slogan\"]:\n",
        "    # Convert the slogan to a list of token indices\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\n",
        "    # Generate progressively longer sequences\n",
        "    for i in range(1, len(token_list)):\n",
        "        input_sequences.append(token_list[:i + 1])\n"
      ],
      "metadata": {
        "id": "1Sl1Id28oXgu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The input sequences created above are of **varying lengths**, which will be a problem when training our LSTM model. LSTMs require input sequences of **equal length**. So, we need to **pad** shorter sequences by **prepending zeros** until they match the length of the longest sequence.  \n",
        "\n",
        "For example, if the longest sequence has **10 tokens**, our padded sequences will look like this:\n",
        "\n",
        "<center>\n",
        "\n",
        "| Input Sequence                     | Padded Sequence                         |\n",
        "|-------------------------------------|-----------------------------------------|\n",
        "| [1, 2]                              | [0, 0, 0, 0, 0, 0, 0, 0, 1, 2]         |\n",
        "| [1, 2, 3]                           | [0, 0, 0, 0, 0, 0, 0, 1, 2, 3]         |\n",
        "| [1, 2, 3, 4]                        | [0, 0, 0, 0, 0, 0, 1, 2, 3, 4]         |\n",
        "| [1, 2, 3, 4, 5]                     | [0, 0, 0, 0, 0, 1, 2, 3, 4, 5]         |\n",
        "| [1, 2, 3, 4, 5, 6]                  | [0, 0, 0, 0, 1, 2, 3, 4, 5, 6]         |\n",
        "| [1, 2, 3, 4, 5, 6, 7]               | [0, 0, 0, 1, 2, 3, 4, 5, 6, 7]         |\n",
        "| [1, 2, 3, 4, 5, 6, 7, 8]            | [0, 0, 1, 2, 3, 4, 5, 6, 7, 8]         |\n",
        "\n",
        "</center>\n",
        "\n",
        "In the cell below, write code that **finds the length of the longest sequence** in **input_sequences** and stores this value in a variable named **max_seq_len**.\n"
      ],
      "metadata": {
        "id": "8lY8QgnST-MA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the length of the longest sequence\n",
        "max_seq_len = max(len(seq) for seq in input_sequences)\n",
        "\n",
        "# Display the result\n",
        "print(\"Maximum sequence length:\", max_seq_len)\n"
      ],
      "metadata": {
        "id": "-xqxBtBoT-vF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0c17901-04bd-42f2-b142-e0d89f6c026f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum sequence length: 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the cell below to pad the input sequences so they are all the same length as **max_seq_length**."
      ],
      "metadata": {
        "id": "RGE2b-LsYPBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = pad_sequences(input_sequences, maxlen=max_seq_len, padding=\"pre\")"
      ],
      "metadata": {
        "id": "3sRJZGE-YPo8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Data for Slogan Generator\n",
        "\n",
        "The input sequences generated will be used as our training data. Our LSTM needs to learn how to predict the **next word** in a sequence.  \n",
        "\n",
        "The inputs for our model will be the input sequences **excluding the last token index** and the outputs will be the **last token index**.  \n",
        "\n",
        "As an example, let us use the input sequence [0, 0, 1, 2, 3, 4, 5, 6, 7, 8] and say it corresponds to the slogan \"computer hardware taking care of small business technology\". When training the model:\n",
        "\n",
        "> Our input **x** will be the input sequence [0, 0, 1, 2, 3, 4, 5, 6, 7] corresponding to \"computer hardware taking care of small\".  \n",
        "> Our output **y** will be [8] which corresponds to \"business\".  \n",
        "\n",
        "In the code cell below, use `input_sequences` to create the following two variables:\n",
        "1. **X_gen** which contains the input sequences excluding the last token index.\n",
        "2. **y_gen** which contains the last token index of the input sequence."
      ],
      "metadata": {
        "id": "xv7pgFrdb6_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare training data for the slogan generator\n",
        "\n",
        "# X_gen will contain all tokens except the last one\n",
        "# y_gen will contain the last token (the word to be predicted)\n",
        "X_gen = np.array([seq[:-1] for seq in input_sequences])\n",
        "y_gen = np.array([seq[-1] for seq in input_sequences])\n",
        "\n",
        "# Display shapes to confirm everything looks right\n",
        "print(\"Shape of X_gen:\", X_gen.shape)\n",
        "print(\"Shape of y_gen:\", y_gen.shape)\n"
      ],
      "metadata": {
        "id": "ARUDFwz9ilkF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0763bdd3-f478-49a6-8c02-4055f0242d50"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_gen: (34736, 14)\n",
            "Shape of y_gen: (34736,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model will output the next word of a sequence over a probability distribution. We need to encode our output variable for this to be possible.\n",
        "\n",
        "In the code cell below, write code that will apply one-hot encoding to **y_gen** using `tf.keras.utils.to_categorical()`. **Maintain the same variable name**.  \n",
        "\n",
        "*Hint: set the `num_classes` (number of classes) parameter to the total number of unique words in the learned vocabulary. You can access this value through a variable that was created when generating input sequences earlier.*"
      ],
      "metadata": {
        "id": "XXKjM3KPkUHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode the output variable y_gen\n",
        "\n",
        "# Convert y_gen to one-hot encoding\n",
        "y_gen = tf.keras.utils.to_categorical(y_gen, num_classes=total_words)\n",
        "\n",
        "# Display the new shape\n",
        "print(\"Shape of one-hot encoded y_gen:\", y_gen.shape)\n"
      ],
      "metadata": {
        "id": "0FpxfR4rkUTK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbb3d608-0d6a-42fc-e4d2-81db22050a7f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of one-hot encoded y_gen: (34736, 6046)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Slogan Generator Architecture\n",
        "\n",
        "In the code cell that follows, configure the LSTM following these steps:\n",
        "\n",
        "1. Create a sequential model using `tf.keras.models.Sequential()`. This model will have an embedding layer, two LSTM layers, and a dense output layer.\n",
        "2. Add an embedding layer that converts words into dense vector representations. This layer should:\n",
        "> *   Have `total_words`as the vocabulary size.\n",
        "> *   Use 100 as an embedding dimension.\n",
        "> *   Takes an input length of `max_seq_len - 1` (excludes the target word).\n",
        "3. Add two LSTM layers.\n",
        "> *   The first LSTM layer should have 150 **and** set `return_sequences` to `True`.\n",
        "> *   The second LSTM layer should have 100 units.\n",
        "4. Add a dense output layer which:\n",
        "> *   Uses `total_words` as the number of units (one for each word in the vocabulary).\n",
        "> *   Uses a softmax activation function.\n",
        "5. Use `Sequential` to put everything together in the correct order to complete the architecture of the LSTM model called **gen_model**.\n"
      ],
      "metadata": {
        "id": "TUraZ3Rbn7Az"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Slogan Generator Architecture\n",
        "# ================================\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "# Create the model\n",
        "gen_model = Sequential()\n",
        "\n",
        "# 1 Embedding layer\n",
        "gen_model.add(Embedding(\n",
        "    input_dim=total_words,       # Vocabulary size\n",
        "    output_dim=100,              # Embedding dimension\n",
        "    input_length=max_seq_len - 1 # Sequence length (excluding target word)\n",
        "))\n",
        "\n",
        "# 2 First LSTM layer\n",
        "gen_model.add(LSTM(150, return_sequences=True))\n",
        "\n",
        "# 3 Second LSTM layer\n",
        "gen_model.add(LSTM(100))\n",
        "\n",
        "# 4 Dense output layer with softmax activation\n",
        "gen_model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "# Display the model summary\n",
        "gen_model.summary()\n"
      ],
      "metadata": {
        "id": "0wnqMaqZn7QP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "60a3787d-80a4-4a20-f8a0-b5f59a85b28f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " embedding (\u001b[38;5;33mEmbedding\u001b[0m)            ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n",
              "\n",
              " lstm (\u001b[38;5;33mLSTM\u001b[0m)                      ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n",
              "\n",
              " lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                    ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n",
              "\n",
              " dense (\u001b[38;5;33mDense\u001b[0m)                    ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
              "\n",
              " embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)            ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n",
              "\n",
              " lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                      ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n",
              "\n",
              " lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                    ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n",
              "\n",
              " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the code cell below, compile `gen_model` using `categorical_crossentropy` loss, an Adam optimiser, and an appropriate metric of your choice.\n"
      ],
      "metadata": {
        "id": "7bBvS8m0rvjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "gen_model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "Tb6NRsGir6XN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Slogan Generation\n",
        "\n",
        "In the code cell below, fit the compiled model on the inputs and outputs, setting the **number of epochs to 50**."
      ],
      "metadata": {
        "id": "ZwdAZH-ysr9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = gen_model.fit(\n",
        "    X_gen,       # input sequences\n",
        "    y_gen,       # one-hot encoded next words\n",
        "    epochs=50,   # number of passes through the dataset\n",
        "    batch_size=64  # optional: adjust for memory or performance\n",
        ")\n"
      ],
      "metadata": {
        "id": "Nkb5HbGCssZg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2c1cb2a-75e9-48ef-943b-a6a6611fe4f2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.0625 - loss: 7.4764\n",
            "Epoch 2/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.0826 - loss: 6.5905\n",
            "Epoch 3/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.1020 - loss: 6.2642\n",
            "Epoch 4/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.1374 - loss: 6.0076\n",
            "Epoch 5/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.1617 - loss: 5.7884\n",
            "Epoch 6/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.1831 - loss: 5.5741\n",
            "Epoch 7/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.2027 - loss: 5.3802\n",
            "Epoch 8/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.2147 - loss: 5.2298\n",
            "Epoch 9/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.2343 - loss: 5.0354\n",
            "Epoch 10/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.2414 - loss: 4.9002\n",
            "Epoch 11/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.2503 - loss: 4.7677\n",
            "Epoch 12/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.2573 - loss: 4.6271\n",
            "Epoch 13/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.2657 - loss: 4.4796\n",
            "Epoch 14/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.2746 - loss: 4.3248\n",
            "Epoch 15/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.2832 - loss: 4.1683\n",
            "Epoch 16/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.2973 - loss: 4.0275\n",
            "Epoch 17/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.3005 - loss: 3.9257\n",
            "Epoch 18/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.3144 - loss: 3.7770\n",
            "Epoch 19/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.3249 - loss: 3.6709\n",
            "Epoch 20/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.3449 - loss: 3.5358\n",
            "Epoch 21/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.3625 - loss: 3.4460\n",
            "Epoch 22/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.3801 - loss: 3.3328\n",
            "Epoch 23/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.3942 - loss: 3.2346\n",
            "Epoch 24/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.4148 - loss: 3.1113\n",
            "Epoch 25/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.4267 - loss: 3.0402\n",
            "Epoch 26/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.4453 - loss: 2.9362\n",
            "Epoch 27/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.4518 - loss: 2.8696\n",
            "Epoch 28/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.4670 - loss: 2.7815\n",
            "Epoch 29/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.4762 - loss: 2.7136\n",
            "Epoch 30/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.4892 - loss: 2.6512\n",
            "Epoch 31/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.4926 - loss: 2.5949\n",
            "Epoch 32/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5079 - loss: 2.5157\n",
            "Epoch 33/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.5186 - loss: 2.4554\n",
            "Epoch 34/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5239 - loss: 2.4040\n",
            "Epoch 35/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.5390 - loss: 2.3393\n",
            "Epoch 36/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5470 - loss: 2.2935\n",
            "Epoch 37/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5511 - loss: 2.2560\n",
            "Epoch 38/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.5574 - loss: 2.2185\n",
            "Epoch 39/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5716 - loss: 2.1383\n",
            "Epoch 40/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.5772 - loss: 2.1092\n",
            "Epoch 41/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.5829 - loss: 2.0778\n",
            "Epoch 42/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.5978 - loss: 2.0126\n",
            "Epoch 43/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5930 - loss: 2.0115\n",
            "Epoch 44/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.6106 - loss: 1.9358\n",
            "Epoch 45/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.6154 - loss: 1.8974\n",
            "Epoch 46/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.6232 - loss: 1.8584\n",
            "Epoch 47/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.6286 - loss: 1.8438\n",
            "Epoch 48/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.6309 - loss: 1.8159\n",
            "Epoch 49/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.6442 - loss: 1.7594\n",
            "Epoch 50/50\n",
            "\u001b[1m543/543\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.6486 - loss: 1.7393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now define a function called `generate_slogan` which will generate a slogan by predicting one word at a time based on a given starting phrase (the `seed_text`). This function will do this using our trained model, `gen_model`.\n",
        "\n",
        "Here is a breakdown of how the algorithm works:  \n",
        "\n",
        "Let us assume the dictionary mapping words to unique indices, `tokenizer.word_index`, looks like this:\n",
        "\n",
        "> `{'computer': 1, 'hardware': 2, 'taking': 3, 'care': 4, 'of': 5}`\n",
        "\n",
        "If the model's predicted index for the next word is 3 (`predicted_index = 3`), the loop will:\n",
        "\n",
        "> Check 'computer' (index 1)  No match  \n",
        "> Check 'hardware' (index 2)  No match  \n",
        "> Check 'taking' (index 3)  Match found!  \n",
        "> Assign output_word = \"taking\" and exit the loop.  \n",
        "\n",
        "The `output_word` will be appended to the `seed_text`, and the process will continue to add words to the `seed_text` until we have reached the maximum number of words **or** an invalid prediction occurs.  \n",
        "\n",
        "Carefully follow the code below and complete the missing parts as guided by the comments."
      ],
      "metadata": {
        "id": "Ln30w1SovlKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_slogan(seed_text, max_words=20):\n",
        "    for _ in range(max_words):\n",
        "\n",
        "        # Tokenising and padding seed_text\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_seq_len-1, padding=\"pre\")\n",
        "\n",
        "        # Use your trained model (gen_model) on token_list to predict the probability distribution of the next word over the vocabulary\n",
        "        predictions = gen_model.predict(token_list, verbose=0)\n",
        "\n",
        "        # From the predicted probabilities, identify the word index with the highest probability\n",
        "        predicted_index = np.argmax(predictions, axis=-1)[0]\n",
        "\n",
        "        output_word = None\n",
        "\n",
        "        # Searching for the word that corresponds to the predicted index\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted_index:\n",
        "                output_word = word\n",
        "                break\n",
        "\n",
        "        # If no valid word is found, algorithm stops\n",
        "        if output_word is None:\n",
        "            break  # out of main loop\n",
        "\n",
        "        # Append the predicted word to seed_text\n",
        "        seed_text += \" \" + output_word\n",
        "\n",
        "    return seed_text\n"
      ],
      "metadata": {
        "id": "oQzoxk5avlXB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Data for Slogan Classifier\n",
        "\n",
        "We will now prepare the data we will use to train our classifier. For our classifier, the inputs will come from the `processed_slogans` column of our DataFrame, `df`. The outputs will be the different industry categories under the `industry` column.\n",
        "\n",
        "In the code cell below, extract the unique values from the `industry` column in the DataFrame and store these in a variable called **industries**."
      ],
      "metadata": {
        "id": "AHAlDcCtwPlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract unique industry categories\n",
        "industries = df['industry'].unique()\n",
        "\n",
        "# Display the result\n",
        "print(industries)\n"
      ],
      "metadata": {
        "id": "-DHQNp-uwcTL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2b65019-07f1-49cb-d710-4e1494f2b291"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['computer hardware' 'health, wellness and fitness' 'internet'\n",
            " 'financial services' 'mechanical or industrial engineering'\n",
            " 'marketing and advertising' 'hospital & health care' 'research'\n",
            " 'information technology and services' 'computer software' 'oil & energy'\n",
            " 'dairy' 'transportation/trucking/railroad' 'design' 'furniture'\n",
            " 'professional training & coaching' 'hospitality' 'textiles'\n",
            " 'food & beverages' 'management consulting' 'medical practice'\n",
            " 'accounting' 'performing arts' 'electrical/electronic manufacturing'\n",
            " 'higher education' 'outsourcing/offshoring'\n",
            " 'venture capital & private equity' 'writing and editing'\n",
            " 'mining & metals' 'construction' 'consumer electronics' 'retail'\n",
            " 'human resources' 'staffing and recruiting' 'farming' 'wholesale'\n",
            " 'events services' 'import and export'\n",
            " 'non-profit organization management' 'machinery' 'information services'\n",
            " 'biotechnology' 'philanthropy' 'law practice' 'real estate'\n",
            " 'graphic design' 'building materials' 'medical devices' 'consumer goods'\n",
            " 'automotive' 'plastics' 'business supplies and equipment'\n",
            " 'civil engineering' 'environmental services' 'architecture & planning'\n",
            " 'investment management' 'publishing' 'industrial automation'\n",
            " 'renewables & environment' 'leisure, travel & tourism'\n",
            " 'education management' 'luxury goods & jewelry' 'insurance' 'printing'\n",
            " 'market research' 'restaurants' 'sporting goods' 'consumer services'\n",
            " 'utilities' 'legal services' 'maritime' 'logistics and supply chain'\n",
            " 'government administration' 'think tanks'\n",
            " 'public relations and communications' 'music' 'food production'\n",
            " 'facilities services' 'shipbuilding' 'civic & social organization'\n",
            " 'international trade and development' 'media production'\n",
            " 'apparel & fashion' 'museums and institutions'\n",
            " 'translation and localization' 'sports' 'executive office' 'newspapers'\n",
            " 'telecommunications' 'broadcast media' 'fine art' 'e-learning'\n",
            " 'pharmaceuticals' 'warehousing' 'chemicals' 'veterinary' 'online media'\n",
            " 'program development' 'individual & family services' 'animation'\n",
            " 'entertainment' 'commercial real estate' 'photography' 'banking'\n",
            " 'airlines/aviation' 'aviation & aerospace' 'computer & network security'\n",
            " 'gambling & casinos' 'wireless' 'cosmetics' 'computer networking'\n",
            " 'packaging and containers' 'nanotechnology' 'mental health care'\n",
            " 'security and investigations' 'primary/secondary education'\n",
            " 'computer games' 'international affairs' 'defense & space' 'military'\n",
            " 'government relations' 'public safety' 'arts and crafts'\n",
            " 'motion pictures and film' 'religious institutions'\n",
            " 'recreational facilities and services' 'wine and spirits'\n",
            " 'investment banking' 'semiconductors' 'capital markets' 'law enforcement'\n",
            " 'tobacco' 'paper & forest products' 'alternative medicine'\n",
            " 'public policy' 'glass, ceramics & concrete' 'judiciary' 'libraries'\n",
            " 'fund-raising' 'political organization' 'package/freight delivery'\n",
            " 'supermarkets']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a dictionary called `industry_to_index` where each unique industry is mapped to a unique index starting from 0.\n",
        "\n",
        "*Hint: Use the `enumerate()` function.*"
      ],
      "metadata": {
        "id": "OVRLAurq0fz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dictionary mapping industries to unique indices\n",
        "industry_to_index = {industry: idx for idx, industry in enumerate(industries)}\n",
        "\n",
        "# Display the mapping\n",
        "print(industry_to_index)\n"
      ],
      "metadata": {
        "id": "ifWI9iRm0gAQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d10c47f6-3f2b-4965-d4f2-8cc535eac4c7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'computer hardware': 0, 'health, wellness and fitness': 1, 'internet': 2, 'financial services': 3, 'mechanical or industrial engineering': 4, 'marketing and advertising': 5, 'hospital & health care': 6, 'research': 7, 'information technology and services': 8, 'computer software': 9, 'oil & energy': 10, 'dairy': 11, 'transportation/trucking/railroad': 12, 'design': 13, 'furniture': 14, 'professional training & coaching': 15, 'hospitality': 16, 'textiles': 17, 'food & beverages': 18, 'management consulting': 19, 'medical practice': 20, 'accounting': 21, 'performing arts': 22, 'electrical/electronic manufacturing': 23, 'higher education': 24, 'outsourcing/offshoring': 25, 'venture capital & private equity': 26, 'writing and editing': 27, 'mining & metals': 28, 'construction': 29, 'consumer electronics': 30, 'retail': 31, 'human resources': 32, 'staffing and recruiting': 33, 'farming': 34, 'wholesale': 35, 'events services': 36, 'import and export': 37, 'non-profit organization management': 38, 'machinery': 39, 'information services': 40, 'biotechnology': 41, 'philanthropy': 42, 'law practice': 43, 'real estate': 44, 'graphic design': 45, 'building materials': 46, 'medical devices': 47, 'consumer goods': 48, 'automotive': 49, 'plastics': 50, 'business supplies and equipment': 51, 'civil engineering': 52, 'environmental services': 53, 'architecture & planning': 54, 'investment management': 55, 'publishing': 56, 'industrial automation': 57, 'renewables & environment': 58, 'leisure, travel & tourism': 59, 'education management': 60, 'luxury goods & jewelry': 61, 'insurance': 62, 'printing': 63, 'market research': 64, 'restaurants': 65, 'sporting goods': 66, 'consumer services': 67, 'utilities': 68, 'legal services': 69, 'maritime': 70, 'logistics and supply chain': 71, 'government administration': 72, 'think tanks': 73, 'public relations and communications': 74, 'music': 75, 'food production': 76, 'facilities services': 77, 'shipbuilding': 78, 'civic & social organization': 79, 'international trade and development': 80, 'media production': 81, 'apparel & fashion': 82, 'museums and institutions': 83, 'translation and localization': 84, 'sports': 85, 'executive office': 86, 'newspapers': 87, 'telecommunications': 88, 'broadcast media': 89, 'fine art': 90, 'e-learning': 91, 'pharmaceuticals': 92, 'warehousing': 93, 'chemicals': 94, 'veterinary': 95, 'online media': 96, 'program development': 97, 'individual & family services': 98, 'animation': 99, 'entertainment': 100, 'commercial real estate': 101, 'photography': 102, 'banking': 103, 'airlines/aviation': 104, 'aviation & aerospace': 105, 'computer & network security': 106, 'gambling & casinos': 107, 'wireless': 108, 'cosmetics': 109, 'computer networking': 110, 'packaging and containers': 111, 'nanotechnology': 112, 'mental health care': 113, 'security and investigations': 114, 'primary/secondary education': 115, 'computer games': 116, 'international affairs': 117, 'defense & space': 118, 'military': 119, 'government relations': 120, 'public safety': 121, 'arts and crafts': 122, 'motion pictures and film': 123, 'religious institutions': 124, 'recreational facilities and services': 125, 'wine and spirits': 126, 'investment banking': 127, 'semiconductors': 128, 'capital markets': 129, 'law enforcement': 130, 'tobacco': 131, 'paper & forest products': 132, 'alternative medicine': 133, 'public policy': 134, 'glass, ceramics & concrete': 135, 'judiciary': 136, 'libraries': 137, 'fund-raising': 138, 'political organization': 139, 'package/freight delivery': 140, 'supermarkets': 141}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a new column `industry_index` in your DataFrame by mapping the `industry` column to the indices using the `industry_to_index` dictionary.\n",
        "\n",
        "*Hint: Use the  `map()` function.*"
      ],
      "metadata": {
        "id": "pkr04p3g0vzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Map industry names to their corresponding indices\n",
        "df['industry_index'] = df['industry'].map(industry_to_index)\n",
        "\n",
        "# Display the first few rows to verify\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "bRT8zwHc0v7F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "outputId": "44e6ead3-8d84-48fd-ecb0-bee8690feb3b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                desc  \\\n",
              "0  The latest <company> & Point of Sale tech for ...   \n",
              "1  Easily deliver personalized activities that en...   \n",
              "2  Powerful lead generation software that convert...   \n",
              "3  Twine matches companies to the best digital an...   \n",
              "4  Financial Advisers Norwich, Norfolk - <company...   \n",
              "\n",
              "                                              output           type  \\\n",
              "0           Taking Care of Small Business Technology  headline_long   \n",
              "1              Build World-Class Recreation Programs       headline   \n",
              "2  Most Powerful Lead Generation Software for Mar...  headline_long   \n",
              "3              Hire quality freelancers for your job  headline_long   \n",
              "4                Financial Advisers Norwich, Norfolk       headline   \n",
              "\n",
              "                      company                      industry  \\\n",
              "0            eftpos warehouse             computer hardware   \n",
              "1                       welbi  health, wellness and fitness   \n",
              "2                optinmonster                      internet   \n",
              "3                    twine.fm                      internet   \n",
              "4  mcb financial services ltd            financial services   \n",
              "\n",
              "                          url                   alias  \\\n",
              "0       eftposwarehouse.co.nz        Eftpos Warehouse   \n",
              "1                    welbi.co                   Welbi   \n",
              "2            optinmonster.com            Optinmonster   \n",
              "3                    twine.fm                     NaN   \n",
              "4  mcbfinancialservices.co.uk  Mcb Financial Services   \n",
              "\n",
              "                                         desc_masked  \\\n",
              "0  The latest <company> & Point of Sale tech for ...   \n",
              "1  Easily deliver personalized activities that en...   \n",
              "2  Powerful lead generation software that convert...   \n",
              "3  Twine matches companies to the best digital an...   \n",
              "4  Financial Advisers [country], [country1] - <co...   \n",
              "\n",
              "                                       output_masked  \\\n",
              "0           Taking Care of Small Business Technology   \n",
              "1              Build World-Class Recreation Programs   \n",
              "2  Most Powerful Lead Generation Software for Mar...   \n",
              "3              Hire quality freelancers for your job   \n",
              "4           Financial Advisers [country], [country1]   \n",
              "\n",
              "                                            ent_dict  unsupported first_pos  \\\n",
              "0                              {'[date]': 'monthly'}        False        VB   \n",
              "1                                                 {}        False        VB   \n",
              "2                                                 {}        False        JJ   \n",
              "3                       {'[number]': 'over 260,000'}        False        VB   \n",
              "4  {'[country]': 'Norwich', '[country1]': 'Norfolk'}        False        NN   \n",
              "\n",
              "                                    processed_slogan  \\\n",
              "0           taking care of small business technology   \n",
              "1              build world class recreation programs   \n",
              "2  most powerful lead generation software for mar...   \n",
              "3              hire quality freelancers for your job   \n",
              "4                 financial advisers norwich norfolk   \n",
              "\n",
              "                                     modified_slogan  industry_index  \n",
              "0  computer hardware taking care of small busines...               0  \n",
              "1  health, wellness and fitness build world class...               1  \n",
              "2  internet most powerful lead generation softwar...               2  \n",
              "3     internet hire quality freelancers for your job               2  \n",
              "4  financial services financial advisers norwich ...               3  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-38e3ef68-3c50-42dd-960d-4460b075bd63\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>desc</th>\n",
              "      <th>output</th>\n",
              "      <th>type</th>\n",
              "      <th>company</th>\n",
              "      <th>industry</th>\n",
              "      <th>url</th>\n",
              "      <th>alias</th>\n",
              "      <th>desc_masked</th>\n",
              "      <th>output_masked</th>\n",
              "      <th>ent_dict</th>\n",
              "      <th>unsupported</th>\n",
              "      <th>first_pos</th>\n",
              "      <th>processed_slogan</th>\n",
              "      <th>modified_slogan</th>\n",
              "      <th>industry_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The latest &lt;company&gt; &amp; Point of Sale tech for ...</td>\n",
              "      <td>Taking Care of Small Business Technology</td>\n",
              "      <td>headline_long</td>\n",
              "      <td>eftpos warehouse</td>\n",
              "      <td>computer hardware</td>\n",
              "      <td>eftposwarehouse.co.nz</td>\n",
              "      <td>Eftpos Warehouse</td>\n",
              "      <td>The latest &lt;company&gt; &amp; Point of Sale tech for ...</td>\n",
              "      <td>Taking Care of Small Business Technology</td>\n",
              "      <td>{'[date]': 'monthly'}</td>\n",
              "      <td>False</td>\n",
              "      <td>VB</td>\n",
              "      <td>taking care of small business technology</td>\n",
              "      <td>computer hardware taking care of small busines...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Easily deliver personalized activities that en...</td>\n",
              "      <td>Build World-Class Recreation Programs</td>\n",
              "      <td>headline</td>\n",
              "      <td>welbi</td>\n",
              "      <td>health, wellness and fitness</td>\n",
              "      <td>welbi.co</td>\n",
              "      <td>Welbi</td>\n",
              "      <td>Easily deliver personalized activities that en...</td>\n",
              "      <td>Build World-Class Recreation Programs</td>\n",
              "      <td>{}</td>\n",
              "      <td>False</td>\n",
              "      <td>VB</td>\n",
              "      <td>build world class recreation programs</td>\n",
              "      <td>health, wellness and fitness build world class...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Powerful lead generation software that convert...</td>\n",
              "      <td>Most Powerful Lead Generation Software for Mar...</td>\n",
              "      <td>headline_long</td>\n",
              "      <td>optinmonster</td>\n",
              "      <td>internet</td>\n",
              "      <td>optinmonster.com</td>\n",
              "      <td>Optinmonster</td>\n",
              "      <td>Powerful lead generation software that convert...</td>\n",
              "      <td>Most Powerful Lead Generation Software for Mar...</td>\n",
              "      <td>{}</td>\n",
              "      <td>False</td>\n",
              "      <td>JJ</td>\n",
              "      <td>most powerful lead generation software for mar...</td>\n",
              "      <td>internet most powerful lead generation softwar...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Twine matches companies to the best digital an...</td>\n",
              "      <td>Hire quality freelancers for your job</td>\n",
              "      <td>headline_long</td>\n",
              "      <td>twine.fm</td>\n",
              "      <td>internet</td>\n",
              "      <td>twine.fm</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Twine matches companies to the best digital an...</td>\n",
              "      <td>Hire quality freelancers for your job</td>\n",
              "      <td>{'[number]': 'over 260,000'}</td>\n",
              "      <td>False</td>\n",
              "      <td>VB</td>\n",
              "      <td>hire quality freelancers for your job</td>\n",
              "      <td>internet hire quality freelancers for your job</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Financial Advisers Norwich, Norfolk - &lt;company...</td>\n",
              "      <td>Financial Advisers Norwich, Norfolk</td>\n",
              "      <td>headline</td>\n",
              "      <td>mcb financial services ltd</td>\n",
              "      <td>financial services</td>\n",
              "      <td>mcbfinancialservices.co.uk</td>\n",
              "      <td>Mcb Financial Services</td>\n",
              "      <td>Financial Advisers [country], [country1] - &lt;co...</td>\n",
              "      <td>Financial Advisers [country], [country1]</td>\n",
              "      <td>{'[country]': 'Norwich', '[country1]': 'Norfolk'}</td>\n",
              "      <td>False</td>\n",
              "      <td>NN</td>\n",
              "      <td>financial advisers norwich norfolk</td>\n",
              "      <td>financial services financial advisers norwich ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-38e3ef68-3c50-42dd-960d-4460b075bd63')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-38e3ef68-3c50-42dd-960d-4460b075bd63 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-38e3ef68-3c50-42dd-960d-4460b075bd63');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the DataFrame `df` into training and testing sets, setting aside 20% of the data for the test set. Be sure to set the parameter `stratify=df[\"industry_index\"]`. This ensures that both sets have the same proportion of each class (industry) as in the original dataset, resulting in balanced datasets. Call the training DataFrame `df_train` and the testing DataFrame `df_test`."
      ],
      "metadata": {
        "id": "bICgqYlkCHU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count samples per industry\n",
        "counts = df['industry_index'].value_counts()\n",
        "\n",
        "# Keep only classes with at least 2 samples\n",
        "df_filtered = df[df['industry_index'].isin(counts[counts >= 2].index)]\n",
        "\n",
        "# Split filtered data\n",
        "df_train, df_test = train_test_split(\n",
        "    df_filtered,\n",
        "    test_size=0.2,\n",
        "    stratify=df_filtered[\"industry_index\"],\n",
        "    random_state=42\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "4PdSJ2gYC9Tp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our classifier will use padded slogan sequences as inputs, similar to input sequences used for the slogan generator. The difference is we will not use sequences that get progressively longer, but instead we will use **complete slogans**. This is because our classifier does not need to learn how to predict what word comes next. It needs the full context of a slogan to learn how to accurately predict the industry.  \n",
        "\n",
        "The next steps will walk you through how to create these sequences.  "
      ],
      "metadata": {
        "id": "RQ43WVLD3F9t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We previously created and fitted a `Tokenizer` object called `tokenizer` while preparing data for the slogan generator. Now, we will reuse it to convert words into numerical indices.  \n",
        "\n",
        "In the code cell below, use the `texts_to_sequences()` **method** of `tokenizer` to transform the `processed_slogan` column in **both** the `df_train` and `df_test` DataFrames into sequences of numerical indices. Store the results in variables named `X_train` and `X_test`.\n"
      ],
      "metadata": {
        "id": "_4MDmlZ349bC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert processed slogans to sequences using the tokenizer\n",
        "X_train = tokenizer.texts_to_sequences(df_train[\"processed_slogan\"])\n",
        "X_test = tokenizer.texts_to_sequences(df_test[\"processed_slogan\"])\n",
        "\n",
        "# Display first few sequences to verify\n",
        "print(X_train[:5])\n",
        "print(X_test[:5])\n"
      ],
      "metadata": {
        "id": "Ce5ro9jV3GGs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31207a8a-d438-4d88-b622-dd7d857548b9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1091, 167, 209, 33, 4, 583], [78, 44, 109], [260, 2908, 195, 1456], [1400, 9, 72], [2187, 1, 566, 556, 52, 408]]\n",
            "[[5224, 3, 5225, 621], [1748, 15, 1, 43, 2588, 4, 4918, 1, 842], [1202, 432, 565, 432, 4880, 299, 91], [45, 13, 45, 36, 210], [300, 868, 112]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The slogan sequences are of varying lengths. We will need to pad them the same way we did to the input sequences for the slogan generator. The `pad_sequences()` function can ensure the sequences in `slogan_sequences` have the same length.  \n",
        "\n",
        "In the code cell below, use the `pad_sequences()` function to standardise the `slogan_sequences` lengths. Set the `maxlen` parameter to `max_seq_len`, the `padding` parameter to 0, and assign the resulting padded sequences to the same variables, `X_train` and `X_test`."
      ],
      "metadata": {
        "id": "klUEvtcY8DHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Pad the sequences so they all have the same length\n",
        "X_train = pad_sequences(X_train, maxlen=max_seq_len, padding=\"pre\")\n",
        "X_test = pad_sequences(X_test, maxlen=max_seq_len, padding=\"pre\")\n",
        "\n",
        "# Display shapes to verify\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n"
      ],
      "metadata": {
        "id": "gu30y1hO8DR8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "108dc309-0f15-4b11-a76c-31a8696f2cf2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4272, 15)\n",
            "(1068, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have successfully created training and testing inputs for our model. Now, we will create the outputs - industry categories.\n",
        "\n",
        " In the code cell that follows, use `tf.keras.utils.to_categorical()` to apply one-hot encoding to the `industry_index` column of **both** `df_train` and `df_test` DataFrames. Assign the results to a variables named `y_train` and `y_test`.\n",
        "\n",
        " *Hint: set the `num_classes` parameter to the total number of industries in the DataFrame. The `industries` variable can be used to find this value.*"
      ],
      "metadata": {
        "id": "uIpa6O7MANYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# One-hot encode the industry indices\n",
        "y_train = tf.keras.utils.to_categorical(df_train[\"industry_index\"], num_classes=len(industries))\n",
        "y_test = tf.keras.utils.to_categorical(df_test[\"industry_index\"], num_classes=len(industries))\n",
        "\n",
        "# Display shapes to verify\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n"
      ],
      "metadata": {
        "id": "oOGzb_8BANpE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03d6c954-bc36-4268-b38b-a574ab01d2a4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4272, 142)\n",
            "(1068, 142)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Slogan Classifier Architecture\n",
        "\n",
        "Configure the LSTM classifier following these steps:  \n",
        "\n",
        "\n",
        "1. Create a Sequential model:  \n",
        "   Use `tf.keras.models.Sequential()` to create a sequential model. This model will consist of an embedding layer, two LSTM layers, and a dense output layer.\n",
        "\n",
        "2. Add an embedding layer which will convert words into dense vector representations. Configure this layer with:\n",
        "   > * `total_words` as the vocabulary size.\n",
        "   > * 100 as the embedding dimension.\n",
        "   > * `max_seq_len` as the `input_length` (this is the length of the slogans).\n",
        "\n",
        "3. Add the first LSTM layer. Configure it with:\n",
        "   > * 150 units.\n",
        "   > * Set `return_sequences` to `True` to ensure the layer outputs sequences for the next LSTM layer.\n",
        "\n",
        "4. Add the second LSTM layer which will process the output from the previous LSTM layer. Configure it with:\n",
        "   > * 100 units.\n",
        "   > * No need to set `return_sequences` here (it is the final LSTM layer).\n",
        "\n",
        "5. Add the dense output layer which will classify the data into industries. Configure it with:\n",
        "   > * The number of unique industries as the number of units.\n",
        "   > * The `softmax` activation function to get probabilities for each class (industry).\n",
        "\n",
        "6. Use `Sequential` to arrange all layers in the correct order and complete the architecture of the LSTM model called **class_model**.\n"
      ],
      "metadata": {
        "id": "QlPKC7v-n7dM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "# Build the LSTM classifier model\n",
        "class_model = Sequential([\n",
        "    # Embedding layer\n",
        "    Embedding(input_dim=total_words, output_dim=100, input_length=max_seq_len),\n",
        "\n",
        "    # First LSTM layer\n",
        "    LSTM(150, return_sequences=True),\n",
        "\n",
        "    # Second LSTM layer\n",
        "    LSTM(100),\n",
        "\n",
        "    # Dense output layer for classification\n",
        "    Dense(len(industries), activation='softmax')\n",
        "])\n",
        "\n",
        "# Display the model summary to verify the architecture\n",
        "class_model.summary()\n"
      ],
      "metadata": {
        "id": "JIHaUMT4oC4Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "488a0719-344c-425a-d726-9b2a6fcd3b27"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n",
              "\n",
              " lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                    ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n",
              "\n",
              " lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                    ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n",
              "\n",
              " dense_1 (\u001b[38;5;33mDense\u001b[0m)                  ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
              "\n",
              " embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n",
              "\n",
              " lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                    ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n",
              "\n",
              " lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                    ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n",
              "\n",
              " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the code cell below, compile `class_model` using `categorical_crossentropy` loss, an Adam optimiser, and an appropriate metric of your choice."
      ],
      "metadata": {
        "id": "SlMle0UzGzG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "ltBuXv3TGzPm"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Slogan Classification & Evaluation\n",
        "\n",
        "In the code cell that follows, fit the compiled model on the inputs and outputs, setting **the number of epochs to 50**."
      ],
      "metadata": {
        "id": "4Zvuqmg2HA3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = class_model.fit(\n",
        "    X_train,      # training inputs\n",
        "    y_train,      # training outputs (one-hot encoded)\n",
        "    epochs=50,    # number of training epochs\n",
        "    batch_size=64, # optional, can adjust for memory/performance\n",
        "    validation_data=(X_test, y_test)  # optional, to monitor performance on test set\n",
        ")\n"
      ],
      "metadata": {
        "id": "hZyjCegNHTrc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4c78921-ba68-46b6-aaac-73648e27c354"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9951 - loss: 0.0180 - val_accuracy: 0.1882 - val_loss: 7.4591\n",
            "Epoch 2/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9967 - loss: 0.0142 - val_accuracy: 0.1854 - val_loss: 7.4822\n",
            "Epoch 3/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9970 - loss: 0.0138 - val_accuracy: 0.1845 - val_loss: 7.5024\n",
            "Epoch 4/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9976 - loss: 0.0122 - val_accuracy: 0.1863 - val_loss: 7.5276\n",
            "Epoch 5/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9970 - loss: 0.0150 - val_accuracy: 0.1873 - val_loss: 7.5404\n",
            "Epoch 6/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9973 - loss: 0.0130 - val_accuracy: 0.1901 - val_loss: 7.5632\n",
            "Epoch 7/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9979 - loss: 0.0108 - val_accuracy: 0.1882 - val_loss: 7.5792\n",
            "Epoch 8/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9970 - loss: 0.0113 - val_accuracy: 0.1854 - val_loss: 7.5983\n",
            "Epoch 9/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9956 - loss: 0.0131 - val_accuracy: 0.1863 - val_loss: 7.6149\n",
            "Epoch 10/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9974 - loss: 0.0103 - val_accuracy: 0.1835 - val_loss: 7.6339\n",
            "Epoch 11/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9962 - loss: 0.0134 - val_accuracy: 0.1882 - val_loss: 7.6426\n",
            "Epoch 12/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9968 - loss: 0.0101 - val_accuracy: 0.1854 - val_loss: 7.6677\n",
            "Epoch 13/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9977 - loss: 0.0086 - val_accuracy: 0.1873 - val_loss: 7.6959\n",
            "Epoch 14/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9962 - loss: 0.0111 - val_accuracy: 0.1873 - val_loss: 7.6993\n",
            "Epoch 15/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9971 - loss: 0.0093 - val_accuracy: 0.1882 - val_loss: 7.7143\n",
            "Epoch 16/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9954 - loss: 0.0105 - val_accuracy: 0.1873 - val_loss: 7.7336\n",
            "Epoch 17/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9973 - loss: 0.0086 - val_accuracy: 0.1882 - val_loss: 7.7476\n",
            "Epoch 18/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9982 - loss: 0.0073 - val_accuracy: 0.1854 - val_loss: 7.7654\n",
            "Epoch 19/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9980 - loss: 0.0097 - val_accuracy: 0.1891 - val_loss: 7.7816\n",
            "Epoch 20/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9968 - loss: 0.0091 - val_accuracy: 0.1873 - val_loss: 7.7992\n",
            "Epoch 21/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9971 - loss: 0.0096 - val_accuracy: 0.1891 - val_loss: 7.8167\n",
            "Epoch 22/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9978 - loss: 0.0091 - val_accuracy: 0.1919 - val_loss: 7.8370\n",
            "Epoch 23/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9957 - loss: 0.0111 - val_accuracy: 0.1891 - val_loss: 7.8487\n",
            "Epoch 24/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9967 - loss: 0.0089 - val_accuracy: 0.1882 - val_loss: 7.8635\n",
            "Epoch 25/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9959 - loss: 0.0104 - val_accuracy: 0.1919 - val_loss: 7.8821\n",
            "Epoch 26/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9978 - loss: 0.0073 - val_accuracy: 0.1891 - val_loss: 7.9039\n",
            "Epoch 27/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9970 - loss: 0.0075 - val_accuracy: 0.1873 - val_loss: 7.9296\n",
            "Epoch 28/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9971 - loss: 0.0096 - val_accuracy: 0.1873 - val_loss: 7.9314\n",
            "Epoch 29/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9963 - loss: 0.0085 - val_accuracy: 0.1891 - val_loss: 7.9577\n",
            "Epoch 30/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9990 - loss: 0.0072 - val_accuracy: 0.1873 - val_loss: 7.9738\n",
            "Epoch 31/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9958 - loss: 0.0080 - val_accuracy: 0.1873 - val_loss: 7.9793\n",
            "Epoch 32/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9963 - loss: 0.0082 - val_accuracy: 0.1901 - val_loss: 8.0040\n",
            "Epoch 33/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9974 - loss: 0.0066 - val_accuracy: 0.1863 - val_loss: 8.0243\n",
            "Epoch 34/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9952 - loss: 0.0101 - val_accuracy: 0.1910 - val_loss: 8.0401\n",
            "Epoch 35/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9985 - loss: 0.0075 - val_accuracy: 0.1826 - val_loss: 8.0542\n",
            "Epoch 36/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9972 - loss: 0.0064 - val_accuracy: 0.1891 - val_loss: 8.0603\n",
            "Epoch 37/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9963 - loss: 0.0086 - val_accuracy: 0.1910 - val_loss: 8.0960\n",
            "Epoch 38/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9960 - loss: 0.0075 - val_accuracy: 0.1919 - val_loss: 8.0834\n",
            "Epoch 39/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9974 - loss: 0.0073 - val_accuracy: 0.1901 - val_loss: 8.1124\n",
            "Epoch 40/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9979 - loss: 0.0056 - val_accuracy: 0.1891 - val_loss: 8.1280\n",
            "Epoch 41/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9971 - loss: 0.0063 - val_accuracy: 0.1910 - val_loss: 8.1567\n",
            "Epoch 42/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9976 - loss: 0.0068 - val_accuracy: 0.1882 - val_loss: 8.1682\n",
            "Epoch 43/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9967 - loss: 0.0082 - val_accuracy: 0.1919 - val_loss: 8.1840\n",
            "Epoch 44/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9983 - loss: 0.0056 - val_accuracy: 0.1882 - val_loss: 8.1984\n",
            "Epoch 45/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9968 - loss: 0.0075 - val_accuracy: 0.1901 - val_loss: 8.2179\n",
            "Epoch 46/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9972 - loss: 0.0066 - val_accuracy: 0.1873 - val_loss: 8.2416\n",
            "Epoch 47/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9959 - loss: 0.0080 - val_accuracy: 0.1919 - val_loss: 8.2472\n",
            "Epoch 48/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9966 - loss: 0.0075 - val_accuracy: 0.1919 - val_loss: 8.2651\n",
            "Epoch 49/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9969 - loss: 0.0075 - val_accuracy: 0.1901 - val_loss: 8.2808\n",
            "Epoch 50/50\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9980 - loss: 0.0057 - val_accuracy: 0.1919 - val_loss: 8.2944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model using the testing set. Add a comment on the model's performance."
      ],
      "metadata": {
        "id": "oBNRUAsQHiv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the classifier on the test set\n",
        "loss, accuracy = class_model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "1eTsBN5cHi9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d9a38f3-a2f5-4247-b0fa-ba57657c0df3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 8.2944\n",
            "Test Accuracy: 0.1919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now define a function called `classify_slogan` which takes a slogan as input and predicts the industry it belongs to using the trained model, `class_model`.  \n",
        "\n",
        "Carefully follow the code below and complete the missing parts (indicated by ellipses) as guided by the comments."
      ],
      "metadata": {
        "id": "sHIdfP4tiYnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_slogan(slogan):\n",
        "    # Preprocess the input slogan using the preprocessing function\n",
        "    slogan = preprocess_text(slogan)\n",
        "\n",
        "    # Convert the slogan to a sequence of indices\n",
        "    sequence = tokenizer.texts_to_sequences([slogan])\n",
        "\n",
        "    # Pad the sequence to the same length as training sequences\n",
        "    padded_sequence = pad_sequences(sequence, maxlen=max_seq_len, padding=\"pre\")\n",
        "\n",
        "    # Get predicted probabilities from the classifier\n",
        "    prediction = class_model.predict(padded_sequence, verbose=0)\n",
        "\n",
        "    # Get the index of the industry with the highest probability\n",
        "    predicted_index = np.argmax(prediction, axis=-1)[0]\n",
        "\n",
        "    # Return the predicted industry name\n",
        "    return industries[predicted_index]\n"
      ],
      "metadata": {
        "id": "fNEmTt6piYvE"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combining the two models\n",
        "\n",
        "Run the code cell below to combine the two models: we will first generate a slogan for a company in the \"internet\" industry, then pass the generated slogan to the slogan classifier to see if it correctly classifies it as internet."
      ],
      "metadata": {
        "id": "RZbZQ-TNoDRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "industry = \"internet\"\n",
        "generated_slogan = generate_slogan(industry)\n",
        "predicted_industry = classify_slogan(generated_slogan)\n",
        "\n",
        "print(f\"Generated Slogan: {generated_slogan}\")\n",
        "print(f\"Predicted Industry: {predicted_industry}\")"
      ],
      "metadata": {
        "id": "SMpjs0rFoILz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3f10938-b837-4fac-f630-c08dd43d3634"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Slogan: internet web design agency in pune india in singapore cloud acquisition and capital solutions for be today tricks area companies and\n",
            "Predicted Industry: international affairs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare the results and comment on any differences you notice between the generated slogans and the classifiers predictions in the markdown cell below.\n"
      ],
      "metadata": {
        "id": "_niR0aS5zlQC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparison of Generated Slogan vs Predicted Industry\n",
        "\n",
        "Generated Slogan:\n",
        "internet web design agency in pune india in singapore cloud acquisition and capital solutions for be today tricks area companies and\n",
        "\n",
        "Predicted Industry:\n",
        "international affairs\n",
        "\n",
        "Observations and Comments:\n",
        "\n",
        "Mismatch Between Content and Prediction:\n",
        "\n",
        "The generated slogan clearly describes web design, cloud solutions, and tech services, which is very different from international affairs.\n",
        "\n",
        "Possible Causes for Misclassification:\n",
        "\n",
        "The classifier may have been trained on a limited or imbalanced dataset, so some industries (like tech/digital) are underrepresented.\n",
        "\n",
        "Generated slogans often combine multiple phrases and keywords, which might confuse the classifier and cause it to choose a more frequent or closest matching category.\n",
        "\n",
        "Nature of Generator vs Classifier:\n",
        "\n",
        "The slogan generator predicts the next word based on sequence patterns learned across all industries. It doesnt always stick to a single industry.\n",
        "\n",
        "The classifier only sees the final slogan and tries to assign it to one of the predefined categories. Mixed-industry phrases can mislead the classifier.\n",
        "\n",
        "Conclusion:\n",
        "There is a clear discrepancy between the slogan content and the predicted industry.\n"
      ],
      "metadata": {
        "id": "1i6gJQ9XNGCt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "R17KFEDLzlda"
      }
    }
  ]
}