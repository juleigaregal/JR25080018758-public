{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e3b57d9",
   "metadata": {},
   "source": [
    "#  Fashion MNIST Classification Task\n",
    "\n",
    "##  Objective\n",
    "The goal of this task is to build a neural network model to classify images from the **Fashion MNIST** dataset into one of ten clothing categories.  \n",
    "Will train the model, evaluate its accuracy, and display a confusion matrix to understand misclassifications.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1: Import Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4c3ec1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa672cf",
   "metadata": {},
   "source": [
    "##  Step 2: Load and Prepare the Data\n",
    "\n",
    "Basic transformations to normalize the pixel values of Fashion MNIST images and convert them into tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e54bc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 60000\n",
      "Test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "print('Train samples:', len(train_data))\n",
    "print('Test samples:', len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d31c5b2",
   "metadata": {},
   "source": [
    "## Step 3: Define the Neural Network\n",
    "\n",
    "Define simple feedforward neural network with one hidden layer.  \n",
    "The output layer has 10 units — one for each clothing category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979c2940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (log_softmax): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class FashionNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28*28, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = FashionNN()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86aea81",
   "metadata": {},
   "source": [
    "## Step 4: Choose a Hyperparameter to Tune\n",
    "\n",
    "### Chosen Hyperparameter: Learning Rate (`lr`)\n",
    "\n",
    "The **learning rate** controls how quickly or slowly a model learns during training.  \n",
    "A too-high learning rate causes unstable learning, while a too-low one slows convergence.\n",
    "\n",
    "Use **`lr = 0.001`** because it provides a good balance between stability and convergence speed for this dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38ef39ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 15\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "EPOCHS = 15\n",
    "print(f'Epochs: {EPOCHS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a0e2c8",
   "metadata": {},
   "source": [
    "## Step 5: Train the Model\n",
    "Ttrain the model for 5 epochs and print the average loss after each epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50a16adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Loss: 0.1693\n",
      "Epoch 2/15, Loss: 0.1588\n",
      "Epoch 3/15, Loss: 0.1515\n",
      "Epoch 4/15, Loss: 0.1501\n",
      "Epoch 5/15, Loss: 0.1424\n",
      "Epoch 6/15, Loss: 0.1358\n",
      "Epoch 7/15, Loss: 0.1280\n",
      "Epoch 8/15, Loss: 0.1278\n",
      "Epoch 9/15, Loss: 0.1232\n",
      "Epoch 10/15, Loss: 0.1146\n",
      "Epoch 11/15, Loss: 0.1165\n",
      "Epoch 12/15, Loss: 0.1070\n",
      "Epoch 13/15, Loss: 0.1022\n",
      "Epoch 14/15, Loss: 0.0998\n",
      "Epoch 15/15, Loss: 0.0953\n"
     ]
    }
   ],
   "source": [
    "def train(model, loader):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    return running_loss / len(loader.dataset)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    loss = train(model, train_loader)\n",
    "    print(f'Epoch {epoch+1}/{EPOCHS}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a2a983",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate the Model and Generate Confusion Matrix\n",
    "The confusion matrix shows how well the model predicts each class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c90cc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "             T-shirt/top  Trouser  Pullover  Dress  Coat  Sandal  Shirt  \\\n",
      "T-shirt/top          829        3        24     17     1       1    116   \n",
      "Trouser                2      978         2      9     5       0      3   \n",
      "Pullover              17        2       796     13   114       1     54   \n",
      "Dress                 23        9         8    888    27       1     39   \n",
      "Coat                   0        0        59     27   861       0     49   \n",
      "Sandal                 1        0         0      0     0     969      0   \n",
      "Shirt                109        0        76     23    85       0    696   \n",
      "Sneaker                0        0         0      0     0      38      0   \n",
      "Bag                    4        0         1      4     4       3      5   \n",
      "Ankle boot             1        0         0      0     0      24      0   \n",
      "\n",
      "             Sneaker  Bag  Ankle boot  \n",
      "T-shirt/top        0    9           0  \n",
      "Trouser            0    1           0  \n",
      "Pullover           0    3           0  \n",
      "Dress              0    5           0  \n",
      "Coat               0    4           0  \n",
      "Sandal            19    1          10  \n",
      "Shirt              0   11           0  \n",
      "Sneaker          925    1          36  \n",
      "Bag                1  978           0  \n",
      "Ankle boot        41    0         934  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Define class names\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.tolist())\n",
    "            all_labels.extend(labels.tolist())\n",
    "    return all_preds, all_labels\n",
    "\n",
    "# Evaluate model\n",
    "preds, labels = evaluate_model(model, test_loader)\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(labels, preds)\n",
    "\n",
    "# Convert to DataFrame for labeled display\n",
    "conf_df = pd.DataFrame(conf_matrix, index=class_names, columns=class_names)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10806468",
   "metadata": {},
   "source": [
    "## Confusion Matrix Analysis\n",
    "The confusion matrix shows the performance of the MLP model on the Fashion MNIST test set.  \n",
    "Rows represent **true labels**, columns represent **predicted labels**, and diagonal entries are correct predictions.\n",
    "\n",
    "**Class mapping:**  \n",
    "0 = T-shirt/top, 1 = Trouser, 2 = Pullover, 3 = Dress, 4 = Coat, 5 = Sandal, 6 = Shirt, 7 = Sneaker, 8 = Bag, 9 = Ankle boot\n",
    "\n",
    "### Observations:\n",
    "\n",
    "- **T-shirt/top (0)** is often confused with **Shirt (6)** (116 times).  \n",
    "- **Pullover (2)** is frequently misclassified as **Coat (4)** (114 times).  \n",
    "- **Shirt (6)** is misclassified as **T-shirt/top (0)** (109 times) and **Pullover (2)** (76 times).  \n",
    "- **Sneaker (7)** and **Ankle boot (9)** show mutual confusion (36 and 41 misclassifications).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bded5d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8854\n",
      "Precision: 0.8855\n",
      "Recall: 0.8854\n",
      "F1-score: 0.8852\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(labels, preds)\n",
    "precision = precision_score(labels, preds, average='macro', zero_division=0)\n",
    "recall = recall_score(labels, preds, average='macro', zero_division=0)\n",
    "f1 = f1_score(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7ecab0",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning Explanation\n",
    "- **Chosen hyperparameter:** Learning rate (`lr=0.001`)\n",
    "- **Reason:** The learning rate strongly affects how fast and how well the model converges.\n",
    "- Lower rates (e.g., 0.0005) converge slower but are stable.\n",
    "- Higher rates (e.g., 0.005) converge faster but risk overshooting.\n",
    "- After tuning, `0.001` with Adam optimizer gave the best stability and accuracy balance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e69933c",
   "metadata": {},
   "source": [
    "## Summary of Fashion MNIST MLP Task\n",
    "\n",
    "### Task Overview\n",
    "- Implemented a **Multilayer Perceptron (MLP)** to classify Fashion MNIST images (10 classes).  \n",
    "- Used PyTorch, including `nn.Module` for the model, `CrossEntropyLoss` for loss, and `Adam` optimizer.  \n",
    "- Dataset was normalized and split into training and test sets using `DataLoader`.\n",
    "\n",
    "### Hyperparameter Tuning\n",
    "- **Chosen hyperparameter:** Learning rate (`lr`)  \n",
    "- **Reason:** Learning rate controls the step size during optimization. Too high → unstable training; too low → slow convergence.  \n",
    "- **Selected value:** `0.001` with Adam optimizer, which provided stable and efficient training.\n",
    "\n",
    "### Model Performance\n",
    "- **Accuracy:** 0.8854  \n",
    "- **Precision (macro):** 0.8855  \n",
    "- **Recall (macro):** 0.8854  \n",
    "- **F1-score (macro):** 0.8852  \n",
    "- The model achieves **>80% accuracy**.\n",
    "\n",
    "### Confusion Matrix Analysis\n",
    "- Diagonal entries show correct predictions; off-diagonal entries indicate misclassifications.  \n",
    "- **Most confused classes:**  \n",
    "  - T-shirt/top ↔ Shirt  \n",
    "  - Pullover ↔ Coat  \n",
    "  - Sneaker ↔ Ankle boot  \n",
    "- Confusions make sense due to visual similarity between these items.\n",
    "\n",
    "### Conclusion\n",
    "- The MLP successfully classifies fashion items with high accuracy.  \n",
    "- Learning rate tuning and model architecture choices significantly impacted performance.  \n",
    "- Confusion matrix reveals specific areas where the model struggles, which can guide further improvement.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
